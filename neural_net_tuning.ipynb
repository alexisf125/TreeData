{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all files in \"data/good_data\" and concatenta them into one dataframe\n",
    "df = pd.concat([pd.read_csv(f\"data/good_data/{file}\") for file in os.listdir(\"data/good_data\")])\n",
    "# keep only common_name, condition, latitude_coordinate, longitude_coordinate, and native columns\n",
    "df = df[['common_name', 'condition', 'latitude_coordinate', 'longitude_coordinate', 'native']]\n",
    "# convert condition to numerical\n",
    "df['condition'] = df['condition'].replace({'excellent': 4, 'good': 3, 'fair': 2, 'poor': 1, 'dead/dying': 0, 'dead': 0})\n",
    "# one hot \"common_name\" column\n",
    "df = pd.get_dummies(df, columns=[\"common_name\"])\n",
    "# one hot native column\n",
    "df = pd.get_dummies(df, columns=[\"native\"])\n",
    "# drop native_no_info column\n",
    "df.drop(columns=['native_no_info'], inplace=True)\n",
    "# drop rows where condition is null\n",
    "df = df.dropna(subset=['condition'])\n",
    "\n",
    "\n",
    "# split into X and y\n",
    "X = df.drop('condition', axis=1)\n",
    "y = df['condition']\n",
    "\n",
    "# convert from boolean to int\n",
    "y = y.astype(int)\n",
    "X = X.astype(float)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got builtin_function_or_method)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# convert data to PyTorch tensors\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(X_train\u001b[39m.\u001b[39;49mvalues)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m      3\u001b[0m X_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(X_test\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(y_train\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mlong()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got builtin_function_or_method)"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert data to PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "X_test = torch.from_numpy(X_test.values).float()\n",
    "y_train = torch.from_numpy(y_train.values).long()\n",
    "y_test = torch.from_numpy(y_test.values).long()\n",
    "\n",
    "# parameters\n",
    "input_size = len(X.columns)\n",
    "num_classes = len(df['condition'].unique())\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m y_batch \u001b[39m=\u001b[39m y_train[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m     23\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[39m=\u001b[39m model(X_batch)\n\u001b[1;32m     25\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     26\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[1;32m     12\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m     13\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not DataFrame"
     ]
    }
   ],
   "source": [
    "# grid search for hyperparameters\n",
    "for learning_rate in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    for batch_size in [100, 200, 300, 400, 500]:\n",
    "        for hidden_size in [100, 200, 300, 400, 500]:\n",
    "            # create model\n",
    "            model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "            # loss and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            # train model\n",
    "            total_step = len(X_train)\n",
    "            loss_list = []\n",
    "            acc_list = []\n",
    "            for epoch in range(num_epochs):\n",
    "                for i in range(0, total_step, batch_size):\n",
    "                    # get batch\n",
    "                    X_batch = X_train[i:i+batch_size]\n",
    "                    y_batch = y_train[i:i+batch_size]\n",
    "                    \n",
    "                    # forward pass\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    loss_list.append(loss.item())\n",
    "                    \n",
    "                    # backward and optimize\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # accuracy\n",
    "                    total = y_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    correct = (predicted == y_batch).sum().item()\n",
    "                    acc_list.append(correct / total)\n",
    "                    \n",
    "                if (epoch+1) % 10 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {correct / total:.4f}')\n",
    "            print(f'learning_rate: {learning_rate}, batch_size: {batch_size}, hidden_size: {hidden_size}, accuracy: {correct / total:.4f}')\n",
    "\n",
    "# test model\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i in range(len(X_test)):\n",
    "        X = X_test[i].unsqueeze(0)\n",
    "        y = y_test[i]\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += y.size(0)\n",
    "        n_correct += (predicted == y).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {acc} %')\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
