{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S1FDQy9YnV5",
        "outputId": "d46dab5b-7476-4e13-e774-54d1275bfe67"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# from sklearn.preprocessing import StandardScaler\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, transforms\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bad pipe message: %s [b'\\x02f\\xe6Ao*\\x9c\\xb6\\xbd_c]\\xd3U_!Rr \\xb1\\xb2R\\xac\\xeb#\\xe5\\\\&~\\x81%*\\xa5\\xafoc\\x15\\x9a\\xabc']\n",
            "Bad pipe message: %s [b'e\\xac\\x96\\xc5=\\xbbc#\\xe5\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00']\n",
            "Bad pipe message: %s [b'\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08']\n",
            "Bad pipe message: %s [b'\\x06\\x04\\x01\\x05']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b\"\\xce\\x06\\xa4>r\\xb7H\\xdcW\\xd0o-\\xfcX\\xb0\\x18\\x95\\x1f\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\"]\n",
            "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 ]\\xa4$Qg\\xa8@\\x85\\xc7\\x8cd\\x9a\\xa8`\\xa5\\xad\\x1cc\\xce\\xe6\\x89\\xd5']\n",
            "Bad pipe message: %s [b\"\\n\\x9e\\xd2\\x82\\xad0\\x98\\x00\\x83\\xdd\\x85S[F\\x90\\xed\\x8c,\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\", b'0\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08']\n",
            "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
            "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
            "Bad pipe message: %s [b'\\x01`\\x82k4\\x10!|\\xefB\\x04\\xb1EP\\x1a\\xffV\\xa7\\x00\\x00>\\xc0\\x14\\xc0']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'9\\x008\\x007\\x006\\xc0\\x0f']\n",
            "Bad pipe message: %s [b'\\xa7\\xd2w\\x94\\x02\\xd2\\xaf\\xdb\\xc1]\\xa5\\xf1\\xf0P\\x15\\x11\\x8e2\\x00\\x00']\n",
            "Bad pipe message: %s [b'', b'\\x02']\n",
            "Bad pipe message: %s [b'\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff']\n",
            "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
            "Bad pipe message: %s [b'\\xca\\x801\\xc5\\xefL\\xdaq\\xbc\\xd7yP6\\xb7\\xf3\\xb0}\\xeb\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0']\n",
            "Bad pipe message: %s [b'\\x16\\x00\\x13\\x00\\x10\\x00\\r']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "# import multiple cities worth of data\n",
        "# data_5 = pd.read_csv('data/Austin_Final_2022-06-18.csv')\n",
        "# data_6 = pd.read_csv('data/Albuquerque_Final_2022-06-18.csv')\n",
        "# data_3 = pd.read_csv('data/StLouis_Final_2022-06-18.csv')\n",
        "# data_4 = pd.read_csv('data/WashingtonDC_Final_2022-06-18.csv')\n",
        "data_1 = pd.read_csv('data/NewYork_Final_2022-06-18.csv')\n",
        "data_2 = pd.read_csv('data/NewYork_Final_2022-06-18_(2).csv')\n",
        "\n",
        "# list of dataframes\n",
        "data_list = [data_1, data_2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu117\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mMX90ZOiip3Y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude_coordinate</th>\n",
              "      <th>latitude_coordinate</th>\n",
              "      <th>condition</th>\n",
              "      <th>American beech</th>\n",
              "      <th>American elm</th>\n",
              "      <th>American hophornbeam</th>\n",
              "      <th>American hornbeam</th>\n",
              "      <th>American larch</th>\n",
              "      <th>American linden</th>\n",
              "      <th>Amur cork tree</th>\n",
              "      <th>...</th>\n",
              "      <th>Virginia pine</th>\n",
              "      <th>Weeping willow</th>\n",
              "      <th>White ash</th>\n",
              "      <th>White oak</th>\n",
              "      <th>White pine</th>\n",
              "      <th>Willow oak</th>\n",
              "      <th>Winged silverbell two</th>\n",
              "      <th>False cypress</th>\n",
              "      <th>Mimosa</th>\n",
              "      <th>Pitch pine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-73.844215</td>\n",
              "      <td>40.723092</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-73.818679</td>\n",
              "      <td>40.794111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-73.936608</td>\n",
              "      <td>40.717581</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-73.934456</td>\n",
              "      <td>40.713537</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-73.975979</td>\n",
              "      <td>40.666778</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 135 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude_coordinate  latitude_coordinate  condition  American beech  \\\n",
              "0            -73.844215            40.723092        2.0               0   \n",
              "1            -73.818679            40.794111        2.0               0   \n",
              "2            -73.936608            40.717581        1.0               0   \n",
              "3            -73.934456            40.713537        1.0               0   \n",
              "4            -73.975979            40.666778        1.0               0   \n",
              "\n",
              "   American elm  American hophornbeam  American hornbeam  American larch  \\\n",
              "0             0                     0                  0               0   \n",
              "1             0                     0                  0               0   \n",
              "2             0                     0                  0               0   \n",
              "3             0                     0                  0               0   \n",
              "4             0                     0                  0               0   \n",
              "\n",
              "   American linden  Amur cork tree  ...  Virginia pine  Weeping willow  \\\n",
              "0                0               0  ...              0               0   \n",
              "1                0               0  ...              0               0   \n",
              "2                0               0  ...              0               0   \n",
              "3                0               0  ...              0               0   \n",
              "4                1               0  ...              0               0   \n",
              "\n",
              "   White ash  White oak  White pine  Willow oak  Winged silverbell two  \\\n",
              "0          0          0           0           0                      0   \n",
              "1          0          0           0           0                      0   \n",
              "2          0          0           0           0                      0   \n",
              "3          0          0           0           0                      0   \n",
              "4          0          0           0           0                      0   \n",
              "\n",
              "   False cypress  Mimosa  Pitch pine  \n",
              "0            NaN     NaN         NaN  \n",
              "1            NaN     NaN         NaN  \n",
              "2            NaN     NaN         NaN  \n",
              "3            NaN     NaN         NaN  \n",
              "4            NaN     NaN         NaN  \n",
              "\n",
              "[5 rows x 135 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loop through the dataframes in data_list\n",
        "for i in range(1, len(data_list) + 1):\n",
        "    # get the dataframe\n",
        "    data = globals()['data_' + str(i)]\n",
        "    \n",
        "    # one hot tree types\n",
        "    tree_types  = pd.get_dummies(data['common_name'])\n",
        "\n",
        "    # drop the common_name column\n",
        "    data = data.drop(columns=['common_name'])\n",
        "\n",
        "    # one hot condition column\n",
        "    data['condition'] = data['condition'].replace({'excellent': 0, 'good': 1, 'fair': 2, 'poor': 3, 'dead/dying': 4, 'dead': 4})\n",
        "    \n",
        "    # create new dataframe with latitude and longitude, tree_types, native, and condition\n",
        "    all_data = pd.concat([data[['longitude_coordinate', 'latitude_coordinate', \n",
        "                                'condition']],\n",
        "                            tree_types],\n",
        "                            axis=1)\n",
        "\n",
        "    # drop rows with NaN values\n",
        "    all_data = all_data.dropna()\n",
        "\n",
        "    # save the dataframe\n",
        "    globals()['all_data_' + str(i)] = all_data\n",
        "\n",
        "# concatenate all the dataframes\n",
        "all_data = pd.concat([all_data_1, all_data_2], axis=0)\n",
        "\n",
        "\n",
        "# # one hot tree types\n",
        "# tree_types  = pd.get_dummies(data['common_name'])\n",
        "\n",
        "# # convert condition to numerical\n",
        "# condition = data['condition'].replace({'excellent': 0, 'good': 1, 'fair': 2, 'poor': 3, 'dead/dying': 4, 'dead': 4})\n",
        "\n",
        "# # one hot native column\n",
        "# native = pd.get_dummies(data['native'])\n",
        "\n",
        "# # create new dataframe with latitude and longitude, tree_types, native, and condition\n",
        "# all_data = pd.concat([data[['longitude_coordinate', 'latitude_coordinate']], \n",
        "#                       tree_types, \n",
        "#                       native, \n",
        "#                       condition], \n",
        "#                       axis=1)\n",
        "\n",
        "\n",
        "all_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 1. 3.]\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# split data back into x and y\n",
        "x_data = all_data.drop(['condition'], axis=1)\n",
        "y_data = all_data['condition']\n",
        "\n",
        "# print unique values in y_data\n",
        "print(y_data.unique())\n",
        "\n",
        "# remove NaN values\n",
        "x_data = x_data.dropna()\n",
        "\n",
        "# print if there are any NaN values in x_data\n",
        "print(x_data.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # standardize x_data\n",
        "# scaler = StandardScaler()\n",
        "# x_data = scaler.fit_transform(x_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split into train and test\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=25)\n",
        "\n",
        "# drop NaN values\n",
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split into x and y\n",
        "x_train = train_data.drop(['condition'], axis=1)\n",
        "y_train = train_data['condition']\n",
        "x_test = test_data.drop(['condition'], axis=1)\n",
        "y_test = test_data['condition']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TyD-HEWqmjpK",
        "outputId": "a2029101-5d1a-4889-c192-c4cf1d852313"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_51776/2207862321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pearson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(cor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10310\u001b[0;31m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10311\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10312\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr_spearman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # compute correlation matrix\n",
        "# corr_df = x_train\n",
        "# cor = corr_df.corr(method='pearson') \n",
        "# # print(cor)\n",
        "\n",
        "# # Plot\n",
        "# fig_corr, ax_corr =plt.subplots()\n",
        "# plt.title(\"Correlation Plot\")\n",
        "# sns.heatmap(cor, cmap=plt.cm.RdYlBu, square=True, ax=ax_corr)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8191193911098434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# train logistic regression model on training data\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(x_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_pred = logistic_regression.predict(x_test)\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'max_accuracy_index' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_51776/1778827112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# find parameters that correspond to max accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_accuracy_index\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_accuracy_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_accuracy_index' is not defined"
          ]
        }
      ],
      "source": [
        "# optimize logistic regression model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# initialize logistic regression model parameters\n",
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(0, 4, 10)   \n",
        "\n",
        "# create empty accuracy list\n",
        "accuracy = []\n",
        "\n",
        "# loop through parameters\n",
        "for p in penalty:\n",
        "    for c in C:\n",
        "        # initialize logistic regression model\n",
        "        logistic_regression = LogisticRegression(penalty=p, C=c, solver='liblinear')\n",
        "        \n",
        "        # fit model\n",
        "        logistic_regression.fit(x_train, y_train)\n",
        "        \n",
        "        # predict on test data\n",
        "        y_pred = logistic_regression.predict(x_test)\n",
        "        \n",
        "        # compute accuracy\n",
        "        accuracy.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# # find max accuracy\n",
        "# max_accuracy = max(accuracy)\n",
        "# print(max_accuracy)\n",
        "\n",
        "# # find index of max accuracy\n",
        "# max_accuracy_index = accuracy.index(max_accuracy)\n",
        "# print(max_accuracy_index)\n",
        "\n",
        "# find parameters that correspond to max accuracy\n",
        "penalty = penalty[max_accuracy_index // len(C)]\n",
        "C = C[max_accuracy_index % len(C)]\n",
        "\n",
        "# plot accuracy\n",
        "plt.plot(accuracy)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "l1\n",
            "5214.00828799969\n",
            "0.5203389830508475\n"
          ]
        }
      ],
      "source": [
        "# return optimal parameters\n",
        "print(penalty)\n",
        "print(C)\n",
        "\n",
        "# initialize logistic regression model with optimal parameters\n",
        "logistic_regression = LogisticRegression(penalty=penalty, C=C, solver='liblinear')\n",
        "\n",
        "# fit model\n",
        "logistic_regression.fit(x_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_pred = logistic_regression.predict(x_test)\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.ToTensor()\n",
        "y_train = y_train.ToTensor()\n",
        "x_test = x_test.ToTensor()\n",
        "y_test = y_test.ToTensor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
