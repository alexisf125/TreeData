{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from ray import tune\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from processed_data.csv for full set of small_set_processed_data.csv for3 city sample\n",
    "df = pd.read_csv('small_set_processed_data.csv')\n",
    "# df = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# split into X and y\n",
    "X = df.drop('condition', axis=1)\n",
    "y = df['condition']\n",
    "\n",
    "# convert from boolean to int\n",
    "y = y.astype(int)\n",
    "X = X.astype(float)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.tensor(X_train.values)\n",
    "X_test = torch.tensor(X_test.values)\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, checkpoint_dir=None, data_dir=None):\n",
    "    # Define the neural network architecture\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1], config[\"hidden_size\"]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(config[\"hidden_size\"], 2)\n",
    "    )\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # Restore from checkpoint, if available\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(checkpoint[\"net\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        epoch = checkpoint[\"epoch\"]\n",
    "        loss = checkpoint[\"loss\"]\n",
    "    else:\n",
    "        epoch = 0\n",
    "        loss = None\n",
    "\n",
    "    # Train the model\n",
    "    while epoch < config[\"num_epochs\"]:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train.float())\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save checkpoint at the end of each epoch\n",
    "        if checkpoint_dir:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save({\n",
    "                \"net\": net.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"loss\": loss\n",
    "            }, checkpoint_path)\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        # Report metrics at the end of each epoch\n",
    "        net.eval()\n",
    "        y_pred = net(X_test.float()).argmax(dim=1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        tune.report(mean_accuracy=accuracy, training_iteration=epoch)\n",
    "    \n",
    "    return {\"mean_accuracy\": accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:33:48,903\tWARNING worker.py:1986 -- Warning: The actor ImplicitFunc is very large (78 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-05-08 10:33:50,017\tWARNING util.py:244 -- The `start_trial` operation took 3.687 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:33:50 (running for 00:00:28.80)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00000 | RUNNING  | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | PENDING  |                 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | PENDING  |                 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | PENDING  |                 |           250 | 0.00143448  |\n",
      "| train_model_480b9_00004 | PENDING  |                 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | PENDING  |                 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | PENDING  |                 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:34:00,373\tWARNING util.py:244 -- The `start_trial` operation took 1.895 s, which may be a performance bottleneck.\n",
      "2023-05-08 10:34:05,341\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27716, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:34:00 (running for 00:00:39.15)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00000 | RUNNING  | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | RUNNING  | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | PENDING  |                 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | PENDING  |                 |           250 | 0.00143448  |\n",
      "| train_model_480b9_00004 | PENDING  |                 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | PENDING  |                 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | PENDING  |                 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:34:08,295\tWARNING util.py:244 -- The `start_trial` operation took 1.953 s, which may be a performance bottleneck.\n",
      "2023-05-08 10:34:13,353\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27724, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:34:08 (running for 00:00:47.06)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 3.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (7 PENDING, 3 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00000 | RUNNING  | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | RUNNING  | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | RUNNING  | 127.0.0.1:27726 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | PENDING  |                 |           250 | 0.00143448  |\n",
      "| train_model_480b9_00004 | PENDING  |                 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | PENDING  |                 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | PENDING  |                 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:34:16,147\tWARNING util.py:244 -- The `start_trial` operation took 1.783 s, which may be a performance bottleneck.\n",
      "2023-05-08 10:34:20,363\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27726, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n",
      "2023-05-08 10:34:22,643\tERROR trial_runner.py:1450 -- Trial train_model_480b9_00002: Error happened when processing _ExecutorEventType.TRAINING_RESULT.\n",
      "ray.exceptions.RayTaskError(IndexError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27726, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:34:16 (running for 00:00:54.92)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00000 | RUNNING  | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | RUNNING  | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | RUNNING  | 127.0.0.1:27726 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | RUNNING  | 127.0.0.1:27727 |           250 | 0.00143448  |\n",
      "| train_model_480b9_00004 | PENDING  |                 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | PENDING  |                 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | PENDING  |                 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:34:29 (running for 00:01:08.28)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 2.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (4 ERROR, 4 PENDING, 2 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00004 | RUNNING  | 127.0.0.1:27733 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | RUNNING  | 127.0.0.1:27735 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | PENDING  |                 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "| train_model_480b9_00000 | ERROR    | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | ERROR    | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | ERROR    | 127.0.0.1:27726 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | ERROR    | 127.0.0.1:27727 |           250 | 0.00143448  |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "Number of errored trials: 4\n",
      "+-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name              |   # failures | error file                                                                                                                                          |\n",
      "|-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_model_480b9_00000 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00000_0_hidden_size=500,lr=0.0073_2023-05-08_10-33-46/error.txt |\n",
      "| train_model_480b9_00001 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00001_1_hidden_size=500,lr=0.0011_2023-05-08_10-33-58/error.txt |\n",
      "| train_model_480b9_00002 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00002_2_hidden_size=250,lr=0.0003_2023-05-08_10-34-06/error.txt |\n",
      "| train_model_480b9_00003 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00003_3_hidden_size=250,lr=0.0014_2023-05-08_10-34-14/error.txt |\n",
      "+-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:34:39,946\tWARNING util.py:244 -- The `start_trial` operation took 1.866 s, which may be a performance bottleneck.\n",
      "2023-05-08 10:34:43,393\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27733, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n",
      "2023-05-08 10:34:44,393\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27735, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:34:39 (running for 00:01:18.72)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 3.0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (4 ERROR, 3 PENDING, 3 RUNNING)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00004 | RUNNING  | 127.0.0.1:27733 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | RUNNING  | 127.0.0.1:27735 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | RUNNING  | 127.0.0.1:27743 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | PENDING  |                 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | PENDING  |                 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | PENDING  |                 |           500 | 0.000796499 |\n",
      "| train_model_480b9_00000 | ERROR    | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | ERROR    | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | ERROR    | 127.0.0.1:27726 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | ERROR    | 127.0.0.1:27727 |           250 | 0.00143448  |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "Number of errored trials: 4\n",
      "+-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name              |   # failures | error file                                                                                                                                          |\n",
      "|-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_model_480b9_00000 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00000_0_hidden_size=500,lr=0.0073_2023-05-08_10-33-46/error.txt |\n",
      "| train_model_480b9_00001 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00001_1_hidden_size=500,lr=0.0011_2023-05-08_10-33-58/error.txt |\n",
      "| train_model_480b9_00002 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00002_2_hidden_size=250,lr=0.0003_2023-05-08_10-34-06/error.txt |\n",
      "| train_model_480b9_00003 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00003_3_hidden_size=250,lr=0.0014_2023-05-08_10-34-14/error.txt |\n",
      "+-------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 10:34:48,210\tWARNING util.py:244 -- The `start_trial` operation took 1.900 s, which may be a performance bottleneck.\n",
      "2023-05-08 10:34:52,407\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=27743, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 384, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/1346344073.py\", line 28, in train_model\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/alexisfrankson/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target 2 is out of bounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-08 10:35:09 (running for 00:01:48.19)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 0/4 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21\n",
      "Number of trials: 10/10 (10 ERROR)\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "| Trial name              | status   | loc             |   hidden_size |          lr |\n",
      "|-------------------------+----------+-----------------+---------------+-------------|\n",
      "| train_model_480b9_00000 | ERROR    | 127.0.0.1:27716 |           500 | 0.0073379   |\n",
      "| train_model_480b9_00001 | ERROR    | 127.0.0.1:27724 |           500 | 0.00107933  |\n",
      "| train_model_480b9_00002 | ERROR    | 127.0.0.1:27726 |           250 | 0.000305067 |\n",
      "| train_model_480b9_00003 | ERROR    | 127.0.0.1:27727 |           250 | 0.00143448  |\n",
      "| train_model_480b9_00004 | ERROR    | 127.0.0.1:27733 |           750 | 0.000160031 |\n",
      "| train_model_480b9_00005 | ERROR    | 127.0.0.1:27735 |           250 | 0.0117232   |\n",
      "| train_model_480b9_00006 | ERROR    | 127.0.0.1:27743 |           500 | 0.0409975   |\n",
      "| train_model_480b9_00007 | ERROR    | 127.0.0.1:27744 |          1000 | 0.0134019   |\n",
      "| train_model_480b9_00008 | ERROR    | 127.0.0.1:27750 |           250 | 0.0567886   |\n",
      "| train_model_480b9_00009 | ERROR    | 127.0.0.1:27751 |           500 | 0.000796499 |\n",
      "+-------------------------+----------+-----------------+---------------+-------------+\n",
      "Number of errored trials: 10\n",
      "+-------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name              |   # failures | error file                                                                                                                                           |\n",
      "|-------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_model_480b9_00000 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00000_0_hidden_size=500,lr=0.0073_2023-05-08_10-33-46/error.txt  |\n",
      "| train_model_480b9_00001 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00001_1_hidden_size=500,lr=0.0011_2023-05-08_10-33-58/error.txt  |\n",
      "| train_model_480b9_00002 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00002_2_hidden_size=250,lr=0.0003_2023-05-08_10-34-06/error.txt  |\n",
      "| train_model_480b9_00003 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00003_3_hidden_size=250,lr=0.0014_2023-05-08_10-34-14/error.txt  |\n",
      "| train_model_480b9_00004 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00004_4_hidden_size=750,lr=0.0002_2023-05-08_10-34-26/error.txt  |\n",
      "| train_model_480b9_00005 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00005_5_hidden_size=250,lr=0.0117_2023-05-08_10-34-27/error.txt  |\n",
      "| train_model_480b9_00006 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00006_6_hidden_size=500,lr=0.0410_2023-05-08_10-34-38/error.txt  |\n",
      "| train_model_480b9_00007 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00007_7_hidden_size=1000,lr=0.0134_2023-05-08_10-34-46/error.txt |\n",
      "| train_model_480b9_00008 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00008_8_hidden_size=250,lr=0.0568_2023-05-08_10-34-57/error.txt  |\n",
      "| train_model_480b9_00009 |            1 | /Users/alexisfrankson/ray_results/train_model_2023-05-08_10-33-21/train_model_480b9_00009_9_hidden_size=500,lr=0.0008_2023-05-08_10-34-59/error.txt  |\n",
      "+-------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_model_480b9_00000, train_model_480b9_00001, train_model_480b9_00002, train_model_480b9_00003, train_model_480b9_00004, train_model_480b9_00005, train_model_480b9_00006, train_model_480b9_00007, train_model_480b9_00008, train_model_480b9_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9f/cw5rv8456ld3sk0fl0q1xwjr0000gn/T/ipykernel_22594/2793814546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mreporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIReporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m analysis = tune.run(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_model_480b9_00000, train_model_480b9_00001, train_model_480b9_00002, train_model_480b9_00003, train_model_480b9_00004, train_model_480b9_00005, train_model_480b9_00006, train_model_480b9_00007, train_model_480b9_00008, train_model_480b9_00009])"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"hidden_size\": tune.choice([250, 500, 750, 1000]),\n",
    "    \"num_epochs\": 10,\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"mean_accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(metric_columns=[\"mean_accuracy\", \"training_iteration\"])\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=config,\n",
    "    num_samples=10,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    ")\n",
    "\n",
    "\n",
    "print(analysis.best_config)\n",
    "print(analysis.best_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
