{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from processed_data.csv for full set of small_set_processed_data.csv for3 city sample\n",
    "df = pd.read_csv('stlouis_processed_data.csv')\n",
    "\n",
    "# split into X and y\n",
    "X = df.drop('condition', axis=1)\n",
    "y = df['condition']\n",
    "\n",
    "# convert from boolean to int\n",
    "y = y.astype(int)\n",
    "X = X.astype(float)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# convert to torch tensors\n",
    "X_train = torch.tensor(X_train.values)\n",
    "X_test = torch.tensor(X_test.values)\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_size = len(X.columns)\n",
    "num_classes = len(y.unique())\n",
    "num_epochs = 100\n",
    "hidden_size = 500\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# create model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, X_train, y_train, batch_size):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X.float())\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # calculate train loss\n",
    "        train_outputs = model(X_train.float())\n",
    "        train_loss = criterion(train_outputs, y_train)\n",
    "        train_losses.append(train_loss.item())\n",
    "        # calculate test loss\n",
    "        test_outputs = model(X_test.float())\n",
    "        test_loss = criterion(test_outputs, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# test_losses = []\n",
    "# accuracy_list = []\n",
    "# test_predict = []\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# train model\n",
    "train_loss, test_loss = train_model(model, optimizer, criterion, X_train, y_train, batch_size)\n",
    "# keep an array of predictions on test set\n",
    "# test_predictions = model(X.float()).argmax(axis=1)\n",
    "# test_predict.append(test_predictions)\n",
    "# accuracy = (model(X_test.float()).argmax(axis=1) == y_test).sum().item() / len(y_test)\n",
    "# accuracy_list.append(accuracy)\n",
    "# train_losses.append(train_loss)\n",
    "# test_losses.append(test_loss)\n",
    "# save model\n",
    "torch.save(model.state_dict(), 'stlouis_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5224594772414618]\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracy_list = []\n",
    "accuracy = (model(X_test.float()).argmax(axis=1) == y_test).sum().item() / len(y_test)\n",
    "accuracy_list.append(accuracy)\n",
    "train_losses.append(train_loss)\n",
    "test_losses.append(test_loss)\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83593])\n",
      "2    81883\n",
      "3     1710\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model.load_state_dict(torch.load('stlouis_model.ckpt'))\n",
    "\n",
    "# convert to torch tensors\n",
    "X = torch.tensor(X.values)\n",
    "y = torch.tensor(y.values)\n",
    "\n",
    "predict = model(X.float()).argmax(axis=1)\n",
    "print(predict.shape)\n",
    "\n",
    "# save predictions to a csv\n",
    "predict_stl = pd.DataFrame(predict)\n",
    "predict_stl.to_csv('stl_predictions.csv', index=False)\n",
    "\n",
    "# count each occurence of unique value in predictions\n",
    "print(predict_stl[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>longitude_coordinate</th>\n",
       "      <th>latitude_coordinate</th>\n",
       "      <th>native_introduced</th>\n",
       "      <th>native_naturally_occurring</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-90.281700</td>\n",
       "      <td>38.653678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-90.281757</td>\n",
       "      <td>38.653682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-90.285143</td>\n",
       "      <td>38.648430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-90.280731</td>\n",
       "      <td>38.648149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-90.238763</td>\n",
       "      <td>38.717476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition  longitude_coordinate  latitude_coordinate  native_introduced  \\\n",
       "0        2.0            -90.281700            38.653678                  0   \n",
       "1        2.0            -90.281757            38.653682                  1   \n",
       "2        2.0            -90.285143            38.648430                  1   \n",
       "3        3.0            -90.280731            38.648149                  1   \n",
       "4        2.0            -90.238763            38.717476                  1   \n",
       "\n",
       "   native_naturally_occurring  prediction  \n",
       "0                           0           2  \n",
       "1                           0           2  \n",
       "2                           0           2  \n",
       "3                           0           2  \n",
       "4                           0           2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append prediction column to original dataframe\n",
    "df['prediction'] = predict_stl[0]\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "df.to_csv('stl_full_with_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
